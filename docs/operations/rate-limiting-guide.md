# Guide Rate Limiting - Postry AI

**Date de cr√©ation:** 31 Janvier 2026  
**Derni√®re mise √† jour:** 31 Janvier 2026  
**Version:** 1.0  
**Statut:** ‚úÖ ACTIF

---

## üìã Objectif

Guide complet pour configurer, monitorer et ajuster le rate limiting sur les endpoints critiques de Postry AI.

## üéØ Audience

- **DevOps Engineers:** Configuration et monitoring du rate limiting
- **Backend Developers:** Impl√©mentation et maintenance
- **Support Engineers:** Diagnostic des probl√®mes de rate limiting

---

## üîß Configuration Actuelle

### Endpoints Prot√©g√©s

| Endpoint | Limite | Fen√™tre | Identifiant |
|----------|--------|---------|-------------|
| `/api/auth/persist-on-login` | 10 req | 60s (1 min) | IP address |
| _(Futurs endpoints)_ | - | - | - |

### Variables d'Environnement

**Fichier:** `.env` (local) ou **Vercel Environment Variables** (production)

```bash
# Activer/d√©sactiver rate limiting globalement
RATE_LIMIT_ENABLED=true

# Configuration sp√©cifique persist-on-login
RATE_LIMIT_PERSIST_LOGIN=10        # Nombre max de requ√™tes
RATE_LIMIT_WINDOW_MS=60000         # Fen√™tre en millisecondes (60s)
```

‚ö†Ô∏è **Important:** Ces variables sont lues au d√©marrage du serveur. Modifier ces valeurs n√©cessite un red√©ploiement.

---

## üìä Comment Fonctionne le Rate Limiting

### Architecture

**Impl√©mentation:** In-memory Map (serveur Node.js)

```
Client (IP: 192.168.1.1)
    ‚Üì
Request: POST /api/auth/persist-on-login
    ‚Üì
Rate Limit Check:
  - Identifier: getClientIp(req) ‚Üí "192.168.1.1"
  - Store: Map<IP, { count, resetTime }>
  - Check: count < limit?
    ‚Üì YES
  Allow request (count++)
  Return: 200 OK + rate limit headers
    ‚Üì NO
  Block request
  Return: 429 Too Many Requests
```

### Extraction de l'IP Client

**Ordre de priorit√©:**
1. Header `x-forwarded-for` (proxy/load balancer)
2. Header `x-real-ip` (reverse proxy)
3. Fallback: `"unknown"` (rare en production)

**Exemple:**
```javascript
// Header: x-forwarded-for: "192.168.1.1, 10.0.0.1"
// IP extraite: "192.168.1.1" (premier IP de la liste)
```

### Nettoyage Automatique

**Strat√©gie:** Cleanup interval de 5 minutes

- Toutes les 5 minutes, les entr√©es expir√©es sont supprim√©es du store
- √âvite la croissance infinie de la Map en m√©moire
- Aucun impact sur les performances

---

## üì° Headers Rate Limit dans les R√©ponses

### Headers Standard (RateLimit Specification)

Chaque r√©ponse d'un endpoint prot√©g√© inclut ces headers:

```http
HTTP/1.1 200 OK
X-RateLimit-Limit: 10
X-RateLimit-Remaining: 7
X-RateLimit-Reset: 1706745600
```

**Explication:**
- `X-RateLimit-Limit`: Nombre max de requ√™tes autoris√©es dans la fen√™tre
- `X-RateLimit-Remaining`: Nombre de requ√™tes restantes avant blocage
- `X-RateLimit-Reset`: Timestamp Unix (en secondes) du reset de la limite

### R√©ponse 429 Too Many Requests

Quand la limite est d√©pass√©e:

```http
HTTP/1.1 429 Too Many Requests
X-RateLimit-Limit: 10
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1706745600
Content-Type: application/json

{
  "error": "Too Many Requests",
  "message": "Rate limit exceeded. Try again after 2026-01-31T12:30:00.000Z",
  "retryAfter": 1706745600
}
```

---

## üõ†Ô∏è Monitoring du Rate Limiting

### 1. Logs Serveur (Vercel Logs)

**Rechercher les logs de rate limiting:**

```bash
# Vercel CLI
vercel logs --follow

# Rechercher "Rate limit exceeded"
grep "Rate limit exceeded" logs.txt
```

**Logs typiques:**

```
[2026-01-31T12:00:00.000Z] POST /api/auth/persist-on-login
  IP: 192.168.1.1
  Rate limit exceeded: 11/10 requests
  Reset at: 2026-01-31T12:01:00.000Z
```

### 2. Sentry (Si Configur√©)

**Alertes automatiques:**
- Une alerte Sentry est envoy√©e quand un utilisateur atteint la limite
- Filtre: `level:warning`, `tag:rate-limit`

**Dashboard Sentry:**
1. **Issues** ‚Üí Filter: `rate-limit`
2. Voir la fr√©quence des incidents
3. Identifier les IPs probl√©matiques (abuse)

### 3. M√©triques Cl√©s √† Surveiller

| M√©trique | Description | Seuil d'Alerte |
|----------|-------------|----------------|
| **Rate Limit Blocks** | Nombre de requ√™tes bloqu√©es (429) | > 100/jour (abuse potentiel) |
| **Top Blocked IPs** | IPs les plus bloqu√©es | > 50 blocks/IP/jour |
| **False Positives** | Utilisateurs l√©gitimes bloqu√©s | > 5% des blocks |
| **Reset Rate** | Fr√©quence de reset des compteurs | Devrait √™tre constant |

---

## üîß Ajuster les Limites

### Quand Augmenter la Limite?

**Cas d'usage:**
1. **Trafic l√©gitime √©lev√©:** P√©riode de lancement, campagne marketing
2. **UX d√©grad√©e:** Utilisateurs l√©gitimes bloqu√©s fr√©quemment
3. **Tests automatis√©s:** Environnements de staging/dev

**Proc√©dure:**

1. **Analyser les logs:**
   ```bash
   # Identifier combien d'utilisateurs l√©gitimes sont bloqu√©s
   grep "Rate limit exceeded" logs.txt | grep -v "abuse"
   ```

2. **Calculer la nouvelle limite:**
   - Limite actuelle: 10 req/min
   - Trafic l√©gitime observ√©: 15 req/min (peak)
   - Nouvelle limite recommand√©e: 20 req/min (buffer de 33%)

3. **Mettre √† jour la variable d'environnement:**

   **Vercel Dashboard:**
   - Settings ‚Üí Environment Variables
   - Modifier: `RATE_LIMIT_PERSIST_LOGIN=20`
   - Red√©ployer: `vercel --prod`

4. **Valider:**
   - V√©rifier les headers: `X-RateLimit-Limit: 20`
   - Surveiller les logs pendant 24h

### Quand R√©duire la Limite?

**Cas d'usage:**
1. **Attaque DDoS d√©tect√©e:** Trop de requ√™tes d'IPs suspectes
2. **Abus identifi√©:** Scripts automatis√©s malveillants
3. **R√©duction de charge serveur:** Optimisation des co√ªts

**Proc√©dure:**

1. **Identifier les IPs malveillantes:**
   ```bash
   grep "Rate limit exceeded" logs.txt | sort | uniq -c | sort -nr
   ```

2. **R√©duire temporairement:**
   - Nouvelle limite: `RATE_LIMIT_PERSIST_LOGIN=5`
   - Fen√™tre plus courte: `RATE_LIMIT_WINDOW_MS=30000` (30s)

3. **Activer alerting aggressive:**
   - Envoyer alerte pour chaque block
   - Monitorer en temps r√©el

---

## üö® Sc√©narios d'Incident

### Sc√©nario 1: Utilisateur L√©gitime Bloqu√©

**Sympt√¥me:** User reporte qu'il ne peut pas se connecter (429 error)

**Diagnostic:**
1. V√©rifier les logs: Est-ce un utilisateur l√©gitime ou un bot?
2. V√©rifier l'IP dans les logs: Combien de requ√™tes ont √©t√© faites?
3. V√©rifier le contexte: Lancement d'app mobile, test automatis√©?

**Solution:**
1. **Temporaire:** Augmenter la limite pour cet endpoint
2. **Permanent:** Impl√©menter une whitelist d'IPs (si applicable)
3. **Alternative:** Utiliser authentification pour exemption (user logged = higher limit)

### Sc√©nario 2: Attaque DDoS

**Sympt√¥me:** Milliers de requ√™tes 429 en quelques minutes

**Diagnostic:**
1. Identifier les IPs sources (probablement quelques IPs avec beaucoup de requ√™tes)
2. V√©rifier la distribution g√©ographique (botnet?)
3. V√©rifier le pattern: Requ√™tes espac√©es r√©guli√®rement = bot

**Solution:**
1. **Imm√©diat:** R√©duire drastiquement la limite (RATE_LIMIT=2, WINDOW=10000)
2. **Court terme:** Activer Vercel Edge Firewall (si disponible)
3. **Long terme:** Impl√©menter rate limiting IP-based avec Redis (multi-instance)

### Sc√©nario 3: Rate Limiting Ne Fonctionne Pas

**Sympt√¥me:** Endpoint spamm√© sans blocage (pas de 429)

**Diagnostic:**
1. V√©rifier la variable: `RATE_LIMIT_ENABLED=true`?
2. V√©rifier l'impl√©mentation: Rate limit appliqu√© dans le code?
3. V√©rifier les logs: Aucune trace de rate limiting = bug

**Solution:**
1. V√©rifier le code: `rateLimit(req, config)` est bien appel√©?
2. V√©rifier les mocks en tests: Les tests unitaires passent?
3. Red√©ployer si variable manquante

---

## üîó R√©f√©rences Techniques

### Code Source

- **Rate Limiting Logic:** `lib/rate-limit.ts`
- **Tests Unitaires:** `lib/rate-limit.test.ts` (100% coverage)
- **Endpoint Exemple:** `app/api/auth/persist-on-login/route.ts`

### Standards & Specs

- **IETF RateLimit Specification:** https://datatracker.ietf.org/doc/draft-ietf-httpapi-ratelimit-headers/
- **Vercel Rate Limiting:** https://vercel.com/docs/functions/edge-middleware/middleware-api#rate-limiting
- **Best Practices:** https://cloud.google.com/architecture/rate-limiting-strategies

### Liens Internes

- **Production Deployment:** [production-deployment-guide.md](./production-deployment-guide.md)
- **Alerting Guide:** [alerting-guide.md](./alerting-guide.md)
- **Incident Runbook:** [incident-runbook.md](./incident-runbook.md)
- **Monitoring Metrics:** [monitoring-metrics.md](./monitoring-metrics.md)

---

## üìû Support

**Questions ou probl√®mes avec rate limiting?**

| Type | Contact | Response Time |
|------|---------|---------------|
| **Incident P0** | devops@postry.ai | < 15 min |
| **Question technique** | dev@postry.ai | < 2h (business hours) |
| **Feature request** | Linear (label: rate-limit) | Next sprint |

---

## üß™ Tests & Validation

### Tester le Rate Limiting en Local

```bash
# Start dev server
npm run dev

# Faire 11 requ√™tes rapidement
for i in {1..11}; do
  curl -X POST http://localhost:3000/api/auth/persist-on-login \
    -H "Content-Type: application/json" \
    -d '{ "email": "test@example.com", ... }'
done

# La 11√®me requ√™te devrait retourner 429
```

### Tester en Staging

```bash
# Utiliser un script de load testing
npm run test:rate-limit-staging
```

---

## üìä M√©triques de Succ√®s

**Rate limiting fonctionne correctement si:**

- ‚úÖ 0 incidents d'abuse non d√©tect√©s
- ‚úÖ < 5% de false positives (utilisateurs l√©gitimes bloqu√©s)
- ‚úÖ Temps de r√©ponse 429 < 100ms (blocage instantan√©)
- ‚úÖ Cleanup automatique fonctionne (m√©moire stable)

---

**Cr√©√© par:** Amelia (BMad Dev)  
**Derni√®re r√©vision:** 31 Janvier 2026  
**Prochaine r√©vision:** Lors de changements dans l'impl√©mentation rate limiting
